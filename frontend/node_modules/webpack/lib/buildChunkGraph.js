/*
	MIT License http://www.opensource.org/licenses/mit-license.php
	Author Tobias Koppers @sokra
*/

"use strict";

const AsyncDependencyToInitialChunkError = require("./AsyncDependencyToInitialChunkError");
const { connectChunkGroupParentAndChild ***REMOVED*** = require("./GraphHelpers");
const ModuleGraphConnection = require("./ModuleGraphConnection");
const { getEntryRuntime, mergeRuntime ***REMOVED*** = require("./util/runtime");

/** @typedef {import("./AsyncDependenciesBlock")***REMOVED*** AsyncDependenciesBlock */
/** @typedef {import("./Chunk")***REMOVED*** Chunk */
/** @typedef {import("./ChunkGroup")***REMOVED*** ChunkGroup */
/** @typedef {import("./Compilation")***REMOVED*** Compilation */
/** @typedef {import("./DependenciesBlock")***REMOVED*** DependenciesBlock */
/** @typedef {import("./Dependency")***REMOVED*** Dependency */
/** @typedef {import("./Dependency").DependencyLocation***REMOVED*** DependencyLocation */
/** @typedef {import("./Entrypoint")***REMOVED*** Entrypoint */
/** @typedef {import("./Module")***REMOVED*** Module */
/** @typedef {import("./ModuleGraph")***REMOVED*** ModuleGraph */
/** @typedef {import("./ModuleGraphConnection").ConnectionState***REMOVED*** ConnectionState */
/** @typedef {import("./logging/Logger").Logger***REMOVED*** Logger */
/** @typedef {import("./util/runtime").RuntimeSpec***REMOVED*** RuntimeSpec */

/**
 * @typedef {object***REMOVED*** QueueItem
 * @property {number***REMOVED*** action
 * @property {DependenciesBlock***REMOVED*** block
 * @property {Module***REMOVED*** module
 * @property {Chunk***REMOVED*** chunk
 * @property {ChunkGroup***REMOVED*** chunkGroup
 * @property {ChunkGroupInfo***REMOVED*** chunkGroupInfo
 */

/**
 * @typedef {object***REMOVED*** ChunkGroupInfo
 * @property {ChunkGroup***REMOVED*** chunkGroup the chunk group
 * @property {RuntimeSpec***REMOVED*** runtime the runtimes
 * @property {boolean***REMOVED*** initialized is this chunk group initialized
 * @property {bigint | undefined***REMOVED*** minAvailableModules current minimal set of modules available at this point
 * @property {bigint[]***REMOVED*** availableModulesToBeMerged enqueued updates to the minimal set of available modules
 * @property {Set<Module>=***REMOVED*** skippedItems modules that were skipped because module is already available in parent chunks (need to reconsider when minAvailableModules is shrinking)
 * @property {Set<[Module, ModuleGraphConnection[]]>=***REMOVED*** skippedModuleConnections referenced modules that where skipped because they were not active in this runtime
 * @property {bigint | undefined***REMOVED*** resultingAvailableModules set of modules available including modules from this chunk group
 * @property {Set<ChunkGroupInfo> | undefined***REMOVED*** children set of children chunk groups, that will be revisited when availableModules shrink
 * @property {Set<ChunkGroupInfo> | undefined***REMOVED*** availableSources set of chunk groups that are the source for minAvailableModules
 * @property {Set<ChunkGroupInfo> | undefined***REMOVED*** availableChildren set of chunk groups which depend on the this chunk group as availableSource
 * @property {number***REMOVED*** preOrderIndex next pre order index
 * @property {number***REMOVED*** postOrderIndex next post order index
 * @property {boolean***REMOVED*** chunkLoading has a chunk loading mechanism
 * @property {boolean***REMOVED*** asyncChunks create async chunks
 */

/**
 * @typedef {object***REMOVED*** BlockChunkGroupConnection
 * @property {ChunkGroupInfo***REMOVED*** originChunkGroupInfo origin chunk group
 * @property {ChunkGroup***REMOVED*** chunkGroup referenced chunk group
 */

/** @typedef {(Module | ConnectionState | ModuleGraphConnection)[]***REMOVED*** BlockModulesInTuples */
/** @typedef {(Module | ConnectionState | ModuleGraphConnection[])[]***REMOVED*** BlockModulesInFlattenTuples */
/** @typedef {Map<DependenciesBlock, BlockModulesInFlattenTuples>***REMOVED*** BlockModulesMap */
/** @typedef {Map<Chunk, bigint>***REMOVED*** MaskByChunk */
/** @typedef {Set<DependenciesBlock>***REMOVED*** BlocksWithNestedBlocks */
/** @typedef {Map<AsyncDependenciesBlock, BlockChunkGroupConnection[]>***REMOVED*** BlockConnections */
/** @typedef {Map<ChunkGroup, ChunkGroupInfo>***REMOVED*** ChunkGroupInfoMap */
/** @typedef {Set<ChunkGroup>***REMOVED*** AllCreatedChunkGroups */
/** @typedef {Map<Entrypoint, Module[]>***REMOVED*** InputEntrypointsAndModules */

const ZERO_BIGINT = BigInt(0);
const ONE_BIGINT = BigInt(1);

/**
 * @param {bigint***REMOVED*** mask The mask to test
 * @param {number***REMOVED*** ordinal The ordinal of the bit to test
 * @returns {boolean***REMOVED*** If the ordinal-th bit is set in the mask
 */
const isOrdinalSetInMask = (mask, ordinal) =>
	BigInt.asUintN(1, mask >> BigInt(ordinal)) !== ZERO_BIGINT;

/**
 * @param {ModuleGraphConnection[]***REMOVED*** connections list of connections
 * @param {RuntimeSpec***REMOVED*** runtime for which runtime
 * @returns {ConnectionState***REMOVED*** connection state
 */
const getActiveStateOfConnections = (connections, runtime) => {
	let merged = connections[0].getActiveState(runtime);
	if (merged === true) return true;
	for (let i = 1; i < connections.length; i++) {
		const c = connections[i];
		merged = ModuleGraphConnection.addConnectionStates(
			merged,
			c.getActiveState(runtime)
		);
		if (merged === true) return true;
	***REMOVED***
	return merged;
***REMOVED***;

/**
 * @param {Module***REMOVED*** module module
 * @param {ModuleGraph***REMOVED*** moduleGraph module graph
 * @param {RuntimeSpec***REMOVED*** runtime runtime
 * @param {BlockModulesMap***REMOVED*** blockModulesMap block modules map
 */
const extractBlockModules = (module, moduleGraph, runtime, blockModulesMap) => {
	/** @type {DependenciesBlock | undefined***REMOVED*** */
	let blockCache;
	/** @type {BlockModulesInTuples | undefined***REMOVED*** */
	let modules;

	/** @type {BlockModulesInTuples[]***REMOVED*** */
	const arrays = [];

	/** @type {DependenciesBlock[]***REMOVED*** */
	const queue = [module];
	while (queue.length > 0) {
		const block = /** @type {DependenciesBlock***REMOVED*** */ (queue.pop());
		/** @type {Module[]***REMOVED*** */
		const arr = [];
		arrays.push(arr);
		blockModulesMap.set(block, arr);
		for (const b of block.blocks) {
			queue.push(b);
		***REMOVED***
	***REMOVED***

	for (const connection of moduleGraph.getOutgoingConnections(module)) {
		const d = connection.dependency;
		// We skip connections without dependency
		if (!d) continue;
		const m = connection.module;
		// We skip connections without Module pointer
		if (!m) continue;
		// We skip weak connections
		if (connection.weak) continue;

		const block = moduleGraph.getParentBlock(d);
		let index = moduleGraph.getParentBlockIndex(d);

		// deprecated fallback
		if (index < 0) {
			index = /** @type {DependenciesBlock***REMOVED*** */ (block).dependencies.indexOf(d);
		***REMOVED***

		if (blockCache !== block) {
			modules =
				/** @type {BlockModulesInTuples***REMOVED*** */
				(
					blockModulesMap.get(
						(blockCache = /** @type {DependenciesBlock***REMOVED*** */ (block))
					)
				);
		***REMOVED***

		const i = index * 3;
		/** @type {BlockModulesInTuples***REMOVED*** */
		(modules)[i] = m;
		/** @type {BlockModulesInTuples***REMOVED*** */
		(modules)[i + 1] = connection.getActiveState(runtime);
		/** @type {BlockModulesInTuples***REMOVED*** */
		(modules)[i + 2] = connection;
	***REMOVED***

	for (const modules of arrays) {
		if (modules.length === 0) continue;
		let indexMap;
		let length = 0;
		outer: for (let j = 0; j < modules.length; j += 3) {
			const m = modules[j];
			if (m === undefined) continue;
			const state = /** @type {ConnectionState***REMOVED*** */ (modules[j + 1]);
			const connection = /** @type {ModuleGraphConnection***REMOVED*** */ (modules[j + 2]);
			if (indexMap === undefined) {
				let i = 0;
				for (; i < length; i += 3) {
					if (modules[i] === m) {
						const merged = /** @type {ConnectionState***REMOVED*** */ (modules[i + 1]);
						/** @type {ModuleGraphConnection[]***REMOVED*** */
						(/** @type {unknown***REMOVED*** */ (modules[i + 2])).push(connection);
						if (merged === true) continue outer;
						modules[i + 1] = ModuleGraphConnection.addConnectionStates(
							merged,
							state
						);
						continue outer;
					***REMOVED***
				***REMOVED***
				modules[length] = m;
				length++;
				modules[length] = state;
				length++;
				/** @type {ModuleGraphConnection[]***REMOVED*** */
				(/** @type {unknown***REMOVED*** */ (modules[length])) = [connection];
				length++;
				if (length > 30) {
					// To avoid worse case performance, we will use an index map for
					// linear cost access, which allows to maintain O(n) complexity
					// while keeping allocations down to a minimum
					indexMap = new Map();
					for (let i = 0; i < length; i += 3) {
						indexMap.set(modules[i], i + 1);
					***REMOVED***
				***REMOVED***
			***REMOVED*** else {
				const idx = indexMap.get(m);
				if (idx !== undefined) {
					const merged = /** @type {ConnectionState***REMOVED*** */ (modules[idx]);
					/** @type {ModuleGraphConnection[]***REMOVED*** */
					(/** @type {unknown***REMOVED*** */ (modules[idx + 1])).push(connection);
					if (merged === true) continue;
					modules[idx] = ModuleGraphConnection.addConnectionStates(
						merged,
						state
					);
				***REMOVED*** else {
					modules[length] = m;
					length++;
					modules[length] = state;
					indexMap.set(m, length);
					length++;
					/** @type {ModuleGraphConnection[]***REMOVED*** */
					(
						/** @type {unknown***REMOVED*** */
						(modules[length])
					) = [connection];
					length++;
				***REMOVED***
			***REMOVED***
		***REMOVED***
		modules.length = length;
	***REMOVED***
***REMOVED***;

/**
 * @param {Logger***REMOVED*** logger a logger
 * @param {Compilation***REMOVED*** compilation the compilation
 * @param {InputEntrypointsAndModules***REMOVED*** inputEntrypointsAndModules chunk groups which are processed with the modules
 * @param {ChunkGroupInfoMap***REMOVED*** chunkGroupInfoMap mapping from chunk group to available modules
 * @param {BlockConnections***REMOVED*** blockConnections connection for blocks
 * @param {BlocksWithNestedBlocks***REMOVED*** blocksWithNestedBlocks flag for blocks that have nested blocks
 * @param {AllCreatedChunkGroups***REMOVED*** allCreatedChunkGroups filled with all chunk groups that are created here
 * @param {MaskByChunk***REMOVED*** maskByChunk module content mask by chunk
 */
const visitModules = (
	logger,
	compilation,
	inputEntrypointsAndModules,
	chunkGroupInfoMap,
	blockConnections,
	blocksWithNestedBlocks,
	allCreatedChunkGroups,
	maskByChunk
) => {
	const { moduleGraph, chunkGraph, moduleMemCaches ***REMOVED*** = compilation;

	/** @type {Map<RuntimeSpec, BlockModulesMap>***REMOVED*** */
	const blockModulesRuntimeMap = new Map();

	/** @type {BlockModulesMap | undefined***REMOVED*** */
	let blockModulesMap;

	/** @type {Map<Module, number>***REMOVED*** */
	const ordinalByModule = new Map();

	/**
	 * @param {Module***REMOVED*** module The module to look up
	 * @returns {number***REMOVED*** The ordinal of the module in masks
	 */
	const getModuleOrdinal = module => {
		let ordinal = ordinalByModule.get(module);
		if (ordinal === undefined) {
			ordinal = ordinalByModule.size;
			ordinalByModule.set(module, ordinal);
		***REMOVED***
		return ordinal;
	***REMOVED***;

	for (const chunk of compilation.chunks) {
		let mask = ZERO_BIGINT;
		for (const m of chunkGraph.getChunkModulesIterable(chunk)) {
			mask |= ONE_BIGINT << BigInt(getModuleOrdinal(m));
		***REMOVED***
		maskByChunk.set(chunk, mask);
	***REMOVED***

	/**
	 * @param {DependenciesBlock***REMOVED*** block block
	 * @param {RuntimeSpec***REMOVED*** runtime runtime
	 * @returns {BlockModulesInFlattenTuples | undefined***REMOVED*** block modules in flatten tuples
	 */
	const getBlockModules = (block, runtime) => {
		blockModulesMap = blockModulesRuntimeMap.get(runtime);
		if (blockModulesMap === undefined) {
			/** @type {BlockModulesMap***REMOVED*** */
			blockModulesMap = new Map();
			blockModulesRuntimeMap.set(runtime, blockModulesMap);
		***REMOVED***
		let blockModules = blockModulesMap.get(block);
		if (blockModules !== undefined) return blockModules;
		const module = /** @type {Module***REMOVED*** */ (block.getRootBlock());
		const memCache = moduleMemCaches && moduleMemCaches.get(module);
		if (memCache !== undefined) {
			/** @type {BlockModulesMap***REMOVED*** */
			const map = memCache.provide(
				"bundleChunkGraph.blockModules",
				runtime,
				() => {
					logger.time("visitModules: prepare");
					const map = new Map();
					extractBlockModules(module, moduleGraph, runtime, map);
					logger.timeAggregate("visitModules: prepare");
					return map;
				***REMOVED***
			);
			for (const [block, blockModules] of map)
				blockModulesMap.set(block, blockModules);
			return map.get(block);
		***REMOVED***
		logger.time("visitModules: prepare");
		extractBlockModules(module, moduleGraph, runtime, blockModulesMap);
		blockModules =
			/** @type {BlockModulesInFlattenTuples***REMOVED*** */
			(blockModulesMap.get(block));
		logger.timeAggregate("visitModules: prepare");
		return blockModules;
	***REMOVED***;

	let statProcessedQueueItems = 0;
	let statProcessedBlocks = 0;
	let statConnectedChunkGroups = 0;
	let statProcessedChunkGroupsForMerging = 0;
	let statMergedAvailableModuleSets = 0;
	const statForkedAvailableModules = 0;
	const statForkedAvailableModulesCount = 0;
	const statForkedAvailableModulesCountPlus = 0;
	const statForkedMergedModulesCount = 0;
	const statForkedMergedModulesCountPlus = 0;
	const statForkedResultModulesCount = 0;
	let statChunkGroupInfoUpdated = 0;
	let statChildChunkGroupsReconnected = 0;

	let nextChunkGroupIndex = 0;
	let nextFreeModulePreOrderIndex = 0;
	let nextFreeModulePostOrderIndex = 0;

	/** @type {Map<DependenciesBlock, ChunkGroupInfo>***REMOVED*** */
	const blockChunkGroups = new Map();

	/** @type {Map<ChunkGroupInfo, Set<DependenciesBlock>>***REMOVED*** */
	const blocksByChunkGroups = new Map();

	/** @type {Map<string, ChunkGroupInfo>***REMOVED*** */
	const namedChunkGroups = new Map();

	/** @type {Map<string, ChunkGroupInfo>***REMOVED*** */
	const namedAsyncEntrypoints = new Map();

	/** @type {Set<ChunkGroupInfo>***REMOVED*** */
	const outdatedOrderIndexChunkGroups = new Set();

	const ADD_AND_ENTER_ENTRY_MODULE = 0;
	const ADD_AND_ENTER_MODULE = 1;
	const ENTER_MODULE = 2;
	const PROCESS_BLOCK = 3;
	const PROCESS_ENTRY_BLOCK = 4;
	const LEAVE_MODULE = 5;

	/** @type {QueueItem[]***REMOVED*** */
	let queue = [];

	/** @type {Map<ChunkGroupInfo, Set<[ChunkGroupInfo, QueueItem | null]>>***REMOVED*** */
	const queueConnect = new Map();
	/** @type {Set<ChunkGroupInfo>***REMOVED*** */
	const chunkGroupsForCombining = new Set();

	// Fill queue with entrypoint modules
	// Create ChunkGroupInfo for entrypoints
	for (const [chunkGroup, modules] of inputEntrypointsAndModules) {
		const runtime = getEntryRuntime(
			compilation,
			/** @type {string***REMOVED*** */ (chunkGroup.name),
			chunkGroup.options
		);
		/** @type {ChunkGroupInfo***REMOVED*** */
		const chunkGroupInfo = {
			initialized: false,
			chunkGroup,
			runtime,
			minAvailableModules: undefined,
			availableModulesToBeMerged: [],
			skippedItems: undefined,
			resultingAvailableModules: undefined,
			children: undefined,
			availableSources: undefined,
			availableChildren: undefined,
			preOrderIndex: 0,
			postOrderIndex: 0,
			chunkLoading:
				chunkGroup.options.chunkLoading !== undefined
					? chunkGroup.options.chunkLoading !== false
					: compilation.outputOptions.chunkLoading !== false,
			asyncChunks:
				chunkGroup.options.asyncChunks !== undefined
					? chunkGroup.options.asyncChunks
					: compilation.outputOptions.asyncChunks !== false
		***REMOVED***;
		chunkGroup.index = nextChunkGroupIndex++;
		if (chunkGroup.getNumberOfParents() > 0) {
			// minAvailableModules for child entrypoints are unknown yet, set to undefined.
			// This means no module is added until other sets are merged into
			// this minAvailableModules (by the parent entrypoints)
			const skippedItems = new Set(modules);
			chunkGroupInfo.skippedItems = skippedItems;
			chunkGroupsForCombining.add(chunkGroupInfo);
		***REMOVED*** else {
			// The application may start here: We start with an empty list of available modules
			chunkGroupInfo.minAvailableModules = ZERO_BIGINT;
			const chunk = chunkGroup.getEntrypointChunk();
			for (const module of modules) {
				queue.push({
					action: ADD_AND_ENTER_MODULE,
					block: module,
					module,
					chunk,
					chunkGroup,
					chunkGroupInfo
				***REMOVED***);
			***REMOVED***
		***REMOVED***
		chunkGroupInfoMap.set(chunkGroup, chunkGroupInfo);
		if (chunkGroup.name) {
			namedChunkGroups.set(chunkGroup.name, chunkGroupInfo);
		***REMOVED***
	***REMOVED***
	// Fill availableSources with parent-child dependencies between entrypoints
	for (const chunkGroupInfo of chunkGroupsForCombining) {
		const { chunkGroup ***REMOVED*** = chunkGroupInfo;
		chunkGroupInfo.availableSources = new Set();
		for (const parent of chunkGroup.parentsIterable) {
			const parentChunkGroupInfo =
				/** @type {ChunkGroupInfo***REMOVED*** */
				(chunkGroupInfoMap.get(parent));
			chunkGroupInfo.availableSources.add(parentChunkGroupInfo);
			if (parentChunkGroupInfo.availableChildren === undefined) {
				parentChunkGroupInfo.availableChildren = new Set();
			***REMOVED***
			parentChunkGroupInfo.availableChildren.add(chunkGroupInfo);
		***REMOVED***
	***REMOVED***
	// pop() is used to read from the queue
	// so it need to be reversed to be iterated in
	// correct order
	queue.reverse();

	/** @type {Set<ChunkGroupInfo>***REMOVED*** */
	const outdatedChunkGroupInfo = new Set();
	/** @type {Set<[ChunkGroupInfo, QueueItem | null]>***REMOVED*** */
	const chunkGroupsForMerging = new Set();
	/** @type {QueueItem[]***REMOVED*** */
	let queueDelayed = [];

	/** @type {[Module, ModuleGraphConnection[]][]***REMOVED*** */
	const skipConnectionBuffer = [];
	/** @type {Module[]***REMOVED*** */
	const skipBuffer = [];
	/** @type {QueueItem[]***REMOVED*** */
	const queueBuffer = [];

	/** @type {Module***REMOVED*** */
	let module;
	/** @type {Chunk***REMOVED*** */
	let chunk;
	/** @type {ChunkGroup***REMOVED*** */
	let chunkGroup;
	/** @type {DependenciesBlock***REMOVED*** */
	let block;
	/** @type {ChunkGroupInfo***REMOVED*** */
	let chunkGroupInfo;

	// For each async Block in graph
	/**
	 * @param {AsyncDependenciesBlock***REMOVED*** b iterating over each Async DepBlock
	 * @returns {void***REMOVED***
	 */
	const iteratorBlock = b => {
		// 1. We create a chunk group with single chunk in it for this Block
		// but only once (blockChunkGroups map)
		/** @type {ChunkGroupInfo | undefined***REMOVED*** */
		let cgi = blockChunkGroups.get(b);
		/** @type {ChunkGroup | undefined***REMOVED*** */
		let c;
		/** @type {Entrypoint | undefined***REMOVED*** */
		let entrypoint;
		const entryOptions = b.groupOptions && b.groupOptions.entryOptions;
		if (cgi === undefined) {
			const chunkName = (b.groupOptions && b.groupOptions.name) || b.chunkName;
			if (entryOptions) {
				cgi = namedAsyncEntrypoints.get(/** @type {string***REMOVED*** */ (chunkName));
				if (!cgi) {
					entrypoint = compilation.addAsyncEntrypoint(
						entryOptions,
						module,
						/** @type {DependencyLocation***REMOVED*** */ (b.loc),
						/** @type {string***REMOVED*** */ (b.request)
					);
					maskByChunk.set(entrypoint.chunks[0], ZERO_BIGINT);
					entrypoint.index = nextChunkGroupIndex++;
					cgi = {
						chunkGroup: entrypoint,
						initialized: false,
						runtime:
							entrypoint.options.runtime ||
							/** @type {string | undefined***REMOVED*** */ (entrypoint.name),
						minAvailableModules: ZERO_BIGINT,
						availableModulesToBeMerged: [],
						skippedItems: undefined,
						resultingAvailableModules: undefined,
						children: undefined,
						availableSources: undefined,
						availableChildren: undefined,
						preOrderIndex: 0,
						postOrderIndex: 0,
						chunkLoading:
							entryOptions.chunkLoading !== undefined
								? entryOptions.chunkLoading !== false
								: chunkGroupInfo.chunkLoading,
						asyncChunks:
							entryOptions.asyncChunks !== undefined
								? entryOptions.asyncChunks
								: chunkGroupInfo.asyncChunks
					***REMOVED***;
					chunkGroupInfoMap.set(
						entrypoint,
						/** @type {ChunkGroupInfo***REMOVED*** */
						(cgi)
					);

					chunkGraph.connectBlockAndChunkGroup(b, entrypoint);
					if (chunkName) {
						namedAsyncEntrypoints.set(
							chunkName,
							/** @type {ChunkGroupInfo***REMOVED*** */
							(cgi)
						);
					***REMOVED***
				***REMOVED*** else {
					entrypoint = /** @type {Entrypoint***REMOVED*** */ (cgi.chunkGroup);
					// TODO merge entryOptions
					entrypoint.addOrigin(
						module,
						/** @type {DependencyLocation***REMOVED*** */ (b.loc),
						/** @type {string***REMOVED*** */ (b.request)
					);
					chunkGraph.connectBlockAndChunkGroup(b, entrypoint);
				***REMOVED***

				// 2. We enqueue the DependenciesBlock for traversal
				queueDelayed.push({
					action: PROCESS_ENTRY_BLOCK,
					block: b,
					module,
					chunk: entrypoint.chunks[0],
					chunkGroup: entrypoint,
					chunkGroupInfo: /** @type {ChunkGroupInfo***REMOVED*** */ (cgi)
				***REMOVED***);
			***REMOVED*** else if (!chunkGroupInfo.asyncChunks || !chunkGroupInfo.chunkLoading) {
				// Just queue the block into the current chunk group
				queue.push({
					action: PROCESS_BLOCK,
					block: b,
					module,
					chunk,
					chunkGroup,
					chunkGroupInfo
				***REMOVED***);
			***REMOVED*** else {
				cgi = chunkName ? namedChunkGroups.get(chunkName) : undefined;
				if (!cgi) {
					c = compilation.addChunkInGroup(
						b.groupOptions || b.chunkName,
						module,
						/** @type {DependencyLocation***REMOVED*** */ (b.loc),
						/** @type {string***REMOVED*** */ (b.request)
					);
					maskByChunk.set(c.chunks[0], ZERO_BIGINT);
					c.index = nextChunkGroupIndex++;
					cgi = {
						initialized: false,
						chunkGroup: c,
						runtime: chunkGroupInfo.runtime,
						minAvailableModules: undefined,
						availableModulesToBeMerged: [],
						skippedItems: undefined,
						resultingAvailableModules: undefined,
						children: undefined,
						availableSources: undefined,
						availableChildren: undefined,
						preOrderIndex: 0,
						postOrderIndex: 0,
						chunkLoading: chunkGroupInfo.chunkLoading,
						asyncChunks: chunkGroupInfo.asyncChunks
					***REMOVED***;
					allCreatedChunkGroups.add(c);
					chunkGroupInfoMap.set(c, cgi);
					if (chunkName) {
						namedChunkGroups.set(chunkName, cgi);
					***REMOVED***
				***REMOVED*** else {
					c = cgi.chunkGroup;
					if (c.isInitial()) {
						compilation.errors.push(
							new AsyncDependencyToInitialChunkError(
								/** @type {string***REMOVED*** */ (chunkName),
								module,
								/** @type {DependencyLocation***REMOVED*** */ (b.loc)
							)
						);
						c = chunkGroup;
					***REMOVED*** else {
						c.addOptions(b.groupOptions);
					***REMOVED***
					c.addOrigin(
						module,
						/** @type {DependencyLocation***REMOVED*** */ (b.loc),
						/** @type {string***REMOVED*** */ (b.request)
					);
				***REMOVED***
				blockConnections.set(b, []);
			***REMOVED***
			blockChunkGroups.set(b, /** @type {ChunkGroupInfo***REMOVED*** */ (cgi));
		***REMOVED*** else if (entryOptions) {
			entrypoint = /** @type {Entrypoint***REMOVED*** */ (cgi.chunkGroup);
		***REMOVED*** else {
			c = cgi.chunkGroup;
		***REMOVED***

		if (c !== undefined) {
			// 2. We store the connection for the block
			// to connect it later if needed
			/** @type {BlockChunkGroupConnection[]***REMOVED*** */
			(blockConnections.get(b)).push({
				originChunkGroupInfo: chunkGroupInfo,
				chunkGroup: c
			***REMOVED***);

			// 3. We enqueue the chunk group info creation/updating
			let connectList = queueConnect.get(chunkGroupInfo);
			if (connectList === undefined) {
				connectList = new Set();
				queueConnect.set(chunkGroupInfo, connectList);
			***REMOVED***
			connectList.add([
				/** @type {ChunkGroupInfo***REMOVED*** */ (cgi),
				{
					action: PROCESS_BLOCK,
					block: b,
					module,
					chunk: c.chunks[0],
					chunkGroup: c,
					chunkGroupInfo: /** @type {ChunkGroupInfo***REMOVED*** */ (cgi)
				***REMOVED***
			]);
		***REMOVED*** else if (entrypoint !== undefined) {
			chunkGroupInfo.chunkGroup.addAsyncEntrypoint(entrypoint);
		***REMOVED***
	***REMOVED***;

	/**
	 * @param {DependenciesBlock***REMOVED*** block the block
	 * @returns {void***REMOVED***
	 */
	const processBlock = block => {
		statProcessedBlocks++;
		// get prepared block info
		const blockModules = getBlockModules(block, chunkGroupInfo.runtime);

		if (blockModules !== undefined) {
			const minAvailableModules =
				/** @type {bigint***REMOVED*** */
				(chunkGroupInfo.minAvailableModules);
			// Buffer items because order need to be reversed to get indices correct
			// Traverse all referenced modules
			for (let i = 0, len = blockModules.length; i < len; i += 3) {
				const refModule = /** @type {Module***REMOVED*** */ (blockModules[i]);
				// For single comparisons this might be cheaper
				const isModuleInChunk = chunkGraph.isModuleInChunk(refModule, chunk);

				if (isModuleInChunk) {
					// skip early if already connected
					continue;
				***REMOVED***

				const refOrdinal = /** @type {number***REMOVED*** */ getModuleOrdinal(refModule);
				const activeState = /** @type {ConnectionState***REMOVED*** */ (
					blockModules[i + 1]
				);
				if (activeState !== true) {
					const connections = /** @type {ModuleGraphConnection[]***REMOVED*** */ (
						blockModules[i + 2]
					);
					skipConnectionBuffer.push([refModule, connections]);
					// We skip inactive connections
					if (activeState === false) continue;
				***REMOVED*** else if (isOrdinalSetInMask(minAvailableModules, refOrdinal)) {
					// already in parent chunks, skip it for now
					skipBuffer.push(refModule);
					continue;
				***REMOVED***
				// enqueue, then add and enter to be in the correct order
				// this is relevant with circular dependencies
				queueBuffer.push({
					action: activeState === true ? ADD_AND_ENTER_MODULE : PROCESS_BLOCK,
					block: refModule,
					module: refModule,
					chunk,
					chunkGroup,
					chunkGroupInfo
				***REMOVED***);
			***REMOVED***
			// Add buffered items in reverse order
			if (skipConnectionBuffer.length > 0) {
				let { skippedModuleConnections ***REMOVED*** = chunkGroupInfo;
				if (skippedModuleConnections === undefined) {
					chunkGroupInfo.skippedModuleConnections = skippedModuleConnections =
						new Set();
				***REMOVED***
				for (let i = skipConnectionBuffer.length - 1; i >= 0; i--) {
					skippedModuleConnections.add(skipConnectionBuffer[i]);
				***REMOVED***
				skipConnectionBuffer.length = 0;
			***REMOVED***
			if (skipBuffer.length > 0) {
				let { skippedItems ***REMOVED*** = chunkGroupInfo;
				if (skippedItems === undefined) {
					chunkGroupInfo.skippedItems = skippedItems = new Set();
				***REMOVED***
				for (let i = skipBuffer.length - 1; i >= 0; i--) {
					skippedItems.add(skipBuffer[i]);
				***REMOVED***
				skipBuffer.length = 0;
			***REMOVED***
			if (queueBuffer.length > 0) {
				for (let i = queueBuffer.length - 1; i >= 0; i--) {
					queue.push(queueBuffer[i]);
				***REMOVED***
				queueBuffer.length = 0;
			***REMOVED***
		***REMOVED***

		// Traverse all Blocks
		for (const b of block.blocks) {
			iteratorBlock(b);
		***REMOVED***

		if (block.blocks.length > 0 && module !== block) {
			blocksWithNestedBlocks.add(block);
		***REMOVED***
	***REMOVED***;

	/**
	 * @param {DependenciesBlock***REMOVED*** block the block
	 * @returns {void***REMOVED***
	 */
	const processEntryBlock = block => {
		statProcessedBlocks++;
		// get prepared block info
		const blockModules = getBlockModules(block, chunkGroupInfo.runtime);

		if (blockModules !== undefined) {
			// Traverse all referenced modules in reverse order
			for (let i = blockModules.length - 3; i >= 0; i -= 3) {
				const refModule = /** @type {Module***REMOVED*** */ (blockModules[i]);
				const activeState = /** @type {ConnectionState***REMOVED*** */ (
					blockModules[i + 1]
				);
				// enqueue, then add and enter to be in the correct order
				// this is relevant with circular dependencies
				queue.push({
					action:
						activeState === true ? ADD_AND_ENTER_ENTRY_MODULE : PROCESS_BLOCK,
					block: refModule,
					module: refModule,
					chunk,
					chunkGroup,
					chunkGroupInfo
				***REMOVED***);
			***REMOVED***
		***REMOVED***

		// Traverse all Blocks
		for (const b of block.blocks) {
			iteratorBlock(b);
		***REMOVED***

		if (block.blocks.length > 0 && module !== block) {
			blocksWithNestedBlocks.add(block);
		***REMOVED***
	***REMOVED***;

	const processQueue = () => {
		while (queue.length) {
			statProcessedQueueItems++;
			const queueItem = /** @type {QueueItem***REMOVED*** */ (queue.pop());
			module = queueItem.module;
			block = queueItem.block;
			chunk = queueItem.chunk;
			chunkGroup = queueItem.chunkGroup;
			chunkGroupInfo = queueItem.chunkGroupInfo;

			switch (queueItem.action) {
				case ADD_AND_ENTER_ENTRY_MODULE:
					chunkGraph.connectChunkAndEntryModule(
						chunk,
						module,
						/** @type {Entrypoint***REMOVED*** */ (chunkGroup)
					);
				// fallthrough
				case ADD_AND_ENTER_MODULE: {
					const isModuleInChunk = chunkGraph.isModuleInChunk(module, chunk);

					if (isModuleInChunk) {
						// already connected, skip it
						break;
					***REMOVED***
					// We connect Module and Chunk
					chunkGraph.connectChunkAndModule(chunk, module);
					const moduleOrdinal = getModuleOrdinal(module);
					let chunkMask = /** @type {bigint***REMOVED*** */ (maskByChunk.get(chunk));
					chunkMask |= ONE_BIGINT << BigInt(moduleOrdinal);
					maskByChunk.set(chunk, chunkMask);
				***REMOVED***
				// fallthrough
				case ENTER_MODULE: {
					const index = chunkGroup.getModulePreOrderIndex(module);
					if (index === undefined) {
						chunkGroup.setModulePreOrderIndex(
							module,
							chunkGroupInfo.preOrderIndex++
						);
					***REMOVED***

					if (
						moduleGraph.setPreOrderIndexIfUnset(
							module,
							nextFreeModulePreOrderIndex
						)
					) {
						nextFreeModulePreOrderIndex++;
					***REMOVED***

					// reuse queueItem
					queueItem.action = LEAVE_MODULE;
					queue.push(queueItem);
				***REMOVED***
				// fallthrough
				case PROCESS_BLOCK: {
					processBlock(block);
					break;
				***REMOVED***
				case PROCESS_ENTRY_BLOCK: {
					processEntryBlock(block);
					break;
				***REMOVED***
				case LEAVE_MODULE: {
					const index = chunkGroup.getModulePostOrderIndex(module);
					if (index === undefined) {
						chunkGroup.setModulePostOrderIndex(
							module,
							chunkGroupInfo.postOrderIndex++
						);
					***REMOVED***

					if (
						moduleGraph.setPostOrderIndexIfUnset(
							module,
							nextFreeModulePostOrderIndex
						)
					) {
						nextFreeModulePostOrderIndex++;
					***REMOVED***
					break;
				***REMOVED***
			***REMOVED***
		***REMOVED***
	***REMOVED***;

	/**
	 * @param {ChunkGroupInfo***REMOVED*** chunkGroupInfo The info object for the chunk group
	 * @returns {bigint***REMOVED*** The mask of available modules after the chunk group
	 */
	const calculateResultingAvailableModules = chunkGroupInfo => {
		if (chunkGroupInfo.resultingAvailableModules !== undefined)
			return chunkGroupInfo.resultingAvailableModules;

		let resultingAvailableModules = /** @type {bigint***REMOVED*** */ (
			chunkGroupInfo.minAvailableModules
		);

		// add the modules from the chunk group to the set
		for (const chunk of chunkGroupInfo.chunkGroup.chunks) {
			const mask = /** @type {bigint***REMOVED*** */ (maskByChunk.get(chunk));
			resultingAvailableModules |= mask;
		***REMOVED***

		return (chunkGroupInfo.resultingAvailableModules =
			resultingAvailableModules);
	***REMOVED***;

	const processConnectQueue = () => {
		// Figure out new parents for chunk groups
		// to get new available modules for these children
		for (const [chunkGroupInfo, targets] of queueConnect) {
			// 1. Add new targets to the list of children
			if (chunkGroupInfo.children === undefined) {
				chunkGroupInfo.children = new Set();
			***REMOVED***
			for (const [target] of targets) {
				chunkGroupInfo.children.add(target);
			***REMOVED***

			// 2. Calculate resulting available modules
			const resultingAvailableModules =
				calculateResultingAvailableModules(chunkGroupInfo);

			const runtime = chunkGroupInfo.runtime;

			// 3. Update chunk group info
			for (const [target, processBlock] of targets) {
				target.availableModulesToBeMerged.push(resultingAvailableModules);
				chunkGroupsForMerging.add([target, processBlock]);
				const oldRuntime = target.runtime;
				const newRuntime = mergeRuntime(oldRuntime, runtime);
				if (oldRuntime !== newRuntime) {
					target.runtime = newRuntime;
					outdatedChunkGroupInfo.add(target);
				***REMOVED***
			***REMOVED***

			statConnectedChunkGroups += targets.size;
		***REMOVED***
		queueConnect.clear();
	***REMOVED***;

	const processChunkGroupsForMerging = () => {
		statProcessedChunkGroupsForMerging += chunkGroupsForMerging.size;

		// Execute the merge
		for (const [info, processBlock] of chunkGroupsForMerging) {
			const availableModulesToBeMerged = info.availableModulesToBeMerged;
			const cachedMinAvailableModules = info.minAvailableModules;
			let minAvailableModules = cachedMinAvailableModules;

			statMergedAvailableModuleSets += availableModulesToBeMerged.length;

			for (const availableModules of availableModulesToBeMerged) {
				if (minAvailableModules === undefined) {
					minAvailableModules = availableModules;
				***REMOVED*** else {
					minAvailableModules &= availableModules;
				***REMOVED***
			***REMOVED***

			const changed = minAvailableModules !== cachedMinAvailableModules;

			availableModulesToBeMerged.length = 0;
			if (changed) {
				info.minAvailableModules = minAvailableModules;
				info.resultingAvailableModules = undefined;
				outdatedChunkGroupInfo.add(info);
			***REMOVED***

			if (processBlock) {
				let blocks = blocksByChunkGroups.get(info);
				if (!blocks) {
					blocksByChunkGroups.set(info, (blocks = new Set()));
				***REMOVED***

				// Whether to walk block depends on minAvailableModules and input block.
				// We can treat creating chunk group as a function with 2 input, entry block and minAvailableModules
				// If input is the same, we can skip re-walk
				let needWalkBlock = !info.initialized || changed;
				if (!blocks.has(processBlock.block)) {
					needWalkBlock = true;
					blocks.add(processBlock.block);
				***REMOVED***

				if (needWalkBlock) {
					info.initialized = true;
					queueDelayed.push(processBlock);
				***REMOVED***
			***REMOVED***
		***REMOVED***
		chunkGroupsForMerging.clear();
	***REMOVED***;

	const processChunkGroupsForCombining = () => {
		for (const info of chunkGroupsForCombining) {
			for (const source of /** @type {Set<ChunkGroupInfo>***REMOVED*** */ (
				info.availableSources
			)) {
				if (source.minAvailableModules === undefined) {
					chunkGroupsForCombining.delete(info);
					break;
				***REMOVED***
			***REMOVED***
		***REMOVED***

		for (const info of chunkGroupsForCombining) {
			let availableModules = ZERO_BIGINT;
			// combine minAvailableModules from all resultingAvailableModules
			for (const source of /** @type {Set<ChunkGroupInfo>***REMOVED*** */ (
				info.availableSources
			)) {
				const resultingAvailableModules =
					calculateResultingAvailableModules(source);
				availableModules |= resultingAvailableModules;
			***REMOVED***
			info.minAvailableModules = availableModules;
			info.resultingAvailableModules = undefined;
			outdatedChunkGroupInfo.add(info);
		***REMOVED***
		chunkGroupsForCombining.clear();
	***REMOVED***;

	const processOutdatedChunkGroupInfo = () => {
		statChunkGroupInfoUpdated += outdatedChunkGroupInfo.size;
		// Revisit skipped elements
		for (const info of outdatedChunkGroupInfo) {
			// 1. Reconsider skipped items
			if (info.skippedItems !== undefined) {
				const minAvailableModules =
					/** @type {bigint***REMOVED*** */
					(info.minAvailableModules);
				for (const module of info.skippedItems) {
					const ordinal = getModuleOrdinal(module);
					if (!isOrdinalSetInMask(minAvailableModules, ordinal)) {
						queue.push({
							action: ADD_AND_ENTER_MODULE,
							block: module,
							module,
							chunk: info.chunkGroup.chunks[0],
							chunkGroup: info.chunkGroup,
							chunkGroupInfo: info
						***REMOVED***);
						info.skippedItems.delete(module);
					***REMOVED***
				***REMOVED***
			***REMOVED***

			// 2. Reconsider skipped connections
			if (info.skippedModuleConnections !== undefined) {
				const minAvailableModules =
					/** @type {bigint***REMOVED*** */
					(info.minAvailableModules);
				for (const entry of info.skippedModuleConnections) {
					const [module, connections] = entry;
					const activeState = getActiveStateOfConnections(
						connections,
						info.runtime
					);
					if (activeState === false) continue;
					if (activeState === true) {
						const ordinal = getModuleOrdinal(module);
						info.skippedModuleConnections.delete(entry);
						if (isOrdinalSetInMask(minAvailableModules, ordinal)) {
							/** @type {NonNullable<ChunkGroupInfo["skippedItems"]>***REMOVED*** */
							(info.skippedItems).add(module);
							continue;
						***REMOVED***
					***REMOVED***
					queue.push({
						action: activeState === true ? ADD_AND_ENTER_MODULE : PROCESS_BLOCK,
						block: module,
						module,
						chunk: info.chunkGroup.chunks[0],
						chunkGroup: info.chunkGroup,
						chunkGroupInfo: info
					***REMOVED***);
				***REMOVED***
			***REMOVED***

			// 2. Reconsider children chunk groups
			if (info.children !== undefined) {
				statChildChunkGroupsReconnected += info.children.size;
				for (const cgi of info.children) {
					let connectList = queueConnect.get(info);
					if (connectList === undefined) {
						connectList = new Set();
						queueConnect.set(info, connectList);
					***REMOVED***
					connectList.add([cgi, null]);
				***REMOVED***
			***REMOVED***

			// 3. Reconsider chunk groups for combining
			if (info.availableChildren !== undefined) {
				for (const cgi of info.availableChildren) {
					chunkGroupsForCombining.add(cgi);
				***REMOVED***
			***REMOVED***
			outdatedOrderIndexChunkGroups.add(info);
		***REMOVED***
		outdatedChunkGroupInfo.clear();
	***REMOVED***;

	// Iterative traversal of the Module graph
	// Recursive would be simpler to write but could result in Stack Overflows
	while (queue.length || queueConnect.size) {
		logger.time("visitModules: visiting");
		processQueue();
		logger.timeAggregateEnd("visitModules: prepare");
		logger.timeEnd("visitModules: visiting");

		if (chunkGroupsForCombining.size > 0) {
			logger.time("visitModules: combine available modules");
			processChunkGroupsForCombining();
			logger.timeEnd("visitModules: combine available modules");
		***REMOVED***

		if (queueConnect.size > 0) {
			logger.time("visitModules: calculating available modules");
			processConnectQueue();
			logger.timeEnd("visitModules: calculating available modules");

			if (chunkGroupsForMerging.size > 0) {
				logger.time("visitModules: merging available modules");
				processChunkGroupsForMerging();
				logger.timeEnd("visitModules: merging available modules");
			***REMOVED***
		***REMOVED***

		if (outdatedChunkGroupInfo.size > 0) {
			logger.time("visitModules: check modules for revisit");
			processOutdatedChunkGroupInfo();
			logger.timeEnd("visitModules: check modules for revisit");
		***REMOVED***

		// Run queueDelayed when all items of the queue are processed
		// This is important to get the global indexing correct
		// Async blocks should be processed after all sync blocks are processed
		if (queue.length === 0) {
			const tempQueue = queue;
			queue = queueDelayed.reverse();
			queueDelayed = tempQueue;
		***REMOVED***
	***REMOVED***

	for (const info of outdatedOrderIndexChunkGroups) {
		const { chunkGroup, runtime ***REMOVED*** = info;

		const blocks = blocksByChunkGroups.get(info);

		if (!blocks) {
			continue;
		***REMOVED***

		for (const block of blocks) {
			let preOrderIndex = 0;
			let postOrderIndex = 0;
			/**
			 * @param {DependenciesBlock***REMOVED*** current current
			 * @param {BlocksWithNestedBlocks***REMOVED*** visited visited dependencies blocks
			 */
			const process = (current, visited) => {
				const blockModules =
					/** @type {BlockModulesInFlattenTuples***REMOVED*** */
					(getBlockModules(current, runtime));
				for (let i = 0, len = blockModules.length; i < len; i += 3) {
					const activeState = /** @type {ConnectionState***REMOVED*** */ (
						blockModules[i + 1]
					);
					if (activeState === false) {
						continue;
					***REMOVED***
					const refModule = /** @type {Module***REMOVED*** */ (blockModules[i]);
					if (visited.has(refModule)) {
						continue;
					***REMOVED***

					visited.add(refModule);

					if (refModule) {
						chunkGroup.setModulePreOrderIndex(refModule, preOrderIndex++);
						process(refModule, visited);
						chunkGroup.setModulePostOrderIndex(refModule, postOrderIndex++);
					***REMOVED***
				***REMOVED***
			***REMOVED***;
			process(block, new Set());
		***REMOVED***
	***REMOVED***
	outdatedOrderIndexChunkGroups.clear();
	ordinalByModule.clear();

	logger.log(
		`${statProcessedQueueItems***REMOVED*** queue items processed (${statProcessedBlocks***REMOVED*** blocks)`
	);
	logger.log(`${statConnectedChunkGroups***REMOVED*** chunk groups connected`);
	logger.log(
		`${statProcessedChunkGroupsForMerging***REMOVED*** chunk groups processed for merging (${statMergedAvailableModuleSets***REMOVED*** module sets, ${statForkedAvailableModules***REMOVED*** forked, ${statForkedAvailableModulesCount***REMOVED*** + ${statForkedAvailableModulesCountPlus***REMOVED*** modules forked, ${statForkedMergedModulesCount***REMOVED*** + ${statForkedMergedModulesCountPlus***REMOVED*** modules merged into fork, ${statForkedResultModulesCount***REMOVED*** resulting modules)`
	);
	logger.log(
		`${statChunkGroupInfoUpdated***REMOVED*** chunk group info updated (${statChildChunkGroupsReconnected***REMOVED*** already connected chunk groups reconnected)`
	);
***REMOVED***;

/**
 * @param {Compilation***REMOVED*** compilation the compilation
 * @param {BlocksWithNestedBlocks***REMOVED*** blocksWithNestedBlocks flag for blocks that have nested blocks
 * @param {BlockConnections***REMOVED*** blockConnections connection for blocks
 * @param {MaskByChunk***REMOVED*** maskByChunk mapping from chunk to module mask
 */
const connectChunkGroups = (
	compilation,
	blocksWithNestedBlocks,
	blockConnections,
	maskByChunk
) => {
	const { chunkGraph ***REMOVED*** = compilation;

	/**
	 * Helper function to check if all modules of a chunk are available
	 * @param {ChunkGroup***REMOVED*** chunkGroup the chunkGroup to scan
	 * @param {bigint***REMOVED*** availableModules the comparator set
	 * @returns {boolean***REMOVED*** return true if all modules of a chunk are available
	 */
	const areModulesAvailable = (chunkGroup, availableModules) => {
		for (const chunk of chunkGroup.chunks) {
			const chunkMask = /** @type {bigint***REMOVED*** */ (maskByChunk.get(chunk));
			if ((chunkMask & availableModules) !== chunkMask) return false;
		***REMOVED***
		return true;
	***REMOVED***;

	// For each edge in the basic chunk graph
	for (const [block, connections] of blockConnections) {
		// 1. Check if connection is needed
		// When none of the dependencies need to be connected
		// we can skip all of them
		// It's not possible to filter each item so it doesn't create inconsistent
		// connections and modules can only create one version
		// TODO maybe decide this per runtime
		if (
			// TODO is this needed?
			!blocksWithNestedBlocks.has(block) &&
			connections.every(({ chunkGroup, originChunkGroupInfo ***REMOVED***) =>
				areModulesAvailable(
					chunkGroup,
					/** @type {bigint***REMOVED*** */ (originChunkGroupInfo.resultingAvailableModules)
				)
			)
		) {
			continue;
		***REMOVED***

		// 2. Foreach edge
		for (let i = 0; i < connections.length; i++) {
			const { chunkGroup, originChunkGroupInfo ***REMOVED*** = connections[i];

			// 3. Connect block with chunk
			chunkGraph.connectBlockAndChunkGroup(block, chunkGroup);

			// 4. Connect chunk with parent
			connectChunkGroupParentAndChild(
				originChunkGroupInfo.chunkGroup,
				chunkGroup
			);
		***REMOVED***
	***REMOVED***
***REMOVED***;

/**
 * Remove all unconnected chunk groups
 * @param {Compilation***REMOVED*** compilation the compilation
 * @param {Iterable<ChunkGroup>***REMOVED*** allCreatedChunkGroups all chunk groups that where created before
 */
const cleanupUnconnectedGroups = (compilation, allCreatedChunkGroups) => {
	const { chunkGraph ***REMOVED*** = compilation;

	for (const chunkGroup of allCreatedChunkGroups) {
		if (chunkGroup.getNumberOfParents() === 0) {
			for (const chunk of chunkGroup.chunks) {
				compilation.chunks.delete(chunk);
				chunkGraph.disconnectChunk(chunk);
			***REMOVED***
			chunkGraph.disconnectChunkGroup(chunkGroup);
			chunkGroup.remove();
		***REMOVED***
	***REMOVED***
***REMOVED***;

/**
 * This method creates the Chunk graph from the Module graph
 * @param {Compilation***REMOVED*** compilation the compilation
 * @param {InputEntrypointsAndModules***REMOVED*** inputEntrypointsAndModules chunk groups which are processed with the modules
 * @returns {void***REMOVED***
 */
const buildChunkGraph = (compilation, inputEntrypointsAndModules) => {
	const logger = compilation.getLogger("webpack.buildChunkGraph");

	// SHARED STATE

	/** @type {BlockConnections***REMOVED*** */
	const blockConnections = new Map();

	/** @type {AllCreatedChunkGroups***REMOVED*** */
	const allCreatedChunkGroups = new Set();

	/** @type {ChunkGroupInfoMap***REMOVED*** */
	const chunkGroupInfoMap = new Map();

	/** @type {BlocksWithNestedBlocks***REMOVED*** */
	const blocksWithNestedBlocks = new Set();

	/** @type {MaskByChunk***REMOVED*** */
	const maskByChunk = new Map();

	// PART ONE

	logger.time("visitModules");
	visitModules(
		logger,
		compilation,
		inputEntrypointsAndModules,
		chunkGroupInfoMap,
		blockConnections,
		blocksWithNestedBlocks,
		allCreatedChunkGroups,
		maskByChunk
	);
	logger.timeEnd("visitModules");

	// PART TWO

	logger.time("connectChunkGroups");
	connectChunkGroups(
		compilation,
		blocksWithNestedBlocks,
		blockConnections,
		maskByChunk
	);
	logger.timeEnd("connectChunkGroups");

	for (const [chunkGroup, chunkGroupInfo] of chunkGroupInfoMap) {
		for (const chunk of chunkGroup.chunks)
			chunk.runtime = mergeRuntime(chunk.runtime, chunkGroupInfo.runtime);
	***REMOVED***

	// Cleanup work

	logger.time("cleanup");
	cleanupUnconnectedGroups(compilation, allCreatedChunkGroups);
	logger.timeEnd("cleanup");
***REMOVED***;

module.exports = buildChunkGraph;
